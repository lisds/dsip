

<!DOCTYPE html>


<html lang="en" data-content_root="" >

  <head>
    <meta charset="utf-8" />
    <meta name="viewport" content="width=device-width, initial-scale=1.0" /><meta name="generator" content="Docutils 0.17.1: http://docutils.sourceforge.net/" />

    <title>Fitting models with different cost functions &#8212; Data Science in Practice</title>
  
  
  
  <script data-cfasync="false">
    document.documentElement.dataset.mode = localStorage.getItem("mode") || "";
    document.documentElement.dataset.theme = localStorage.getItem("theme") || "light";
  </script>
  
  <!-- Loaded before other Sphinx assets -->
  <link href="_static/styles/theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/bootstrap.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
<link href="_static/styles/pydata-sphinx-theme.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />

  
  <link href="_static/vendor/fontawesome/6.5.1/css/all.min.css?digest=8d27b9dea8ad943066ae" rel="stylesheet" />
  <link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-solid-900.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-brands-400.woff2" />
<link rel="preload" as="font" type="font/woff2" crossorigin href="_static/vendor/fontawesome/6.5.1/webfonts/fa-regular-400.woff2" />

    <link rel="stylesheet" type="text/css" href="_static/pygments.css" />
    <link rel="stylesheet" type="text/css" href="_static/styles/sphinx-book-theme.css" />
    <link rel="stylesheet" type="text/css" href="_static/togglebutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/copybutton.css" />
    <link rel="stylesheet" type="text/css" href="_static/mystnb.4510f1fc1dee50b3e5859aac5469c37c29e427902b24a333a5f9fcb2f0b3ac41.css" />
    <link rel="stylesheet" type="text/css" href="_static/sphinx-thebe.css" />
    <link rel="stylesheet" type="text/css" href="_static/design-style.1e8bd061cd6da7fc9cf755528e8ffc24.min.css" />
  
  <!-- Pre-loaded scripts that we'll load fully later -->
  <link rel="preload" as="script" href="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae" />
<link rel="preload" as="script" href="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae" />
  <script src="_static/vendor/fontawesome/6.5.1/js/all.min.js?digest=8d27b9dea8ad943066ae"></script>

    <script data-url_root="./" id="documentation_options" src="_static/documentation_options.js"></script>
    <script src="_static/jquery.js"></script>
    <script src="_static/underscore.js"></script>
    <script src="_static/_sphinx_javascript_frameworks_compat.js"></script>
    <script src="_static/doctools.js"></script>
    <script src="_static/sphinx_highlight.js"></script>
    <script src="_static/clipboard.min.js"></script>
    <script src="_static/copybutton.js"></script>
    <script src="_static/scripts/sphinx-book-theme.js"></script>
    <script>let toggleHintShow = 'Click to show';</script>
    <script>let toggleHintHide = 'Click to hide';</script>
    <script>let toggleOpenOnPrint = 'true';</script>
    <script src="_static/togglebutton.js"></script>
    <script>var togglebuttonSelector = '.toggle, .admonition.dropdown';</script>
    <script src="_static/design-tabs.js"></script>
    <script>const THEBE_JS_URL = "https://unpkg.com/thebe@0.8.2/lib/index.js"; const thebe_selector = ".thebe,.cell"; const thebe_selector_input = "pre"; const thebe_selector_output = ".output, .cell_output"</script>
    <script async="async" src="_static/sphinx-thebe.js"></script>
    <script>window.MathJax = {"options": {"processHtmlClass": "tex2jax_process|mathjax_process|math|output_area"}}</script>
    <script defer="defer" src="https://cdn.jsdelivr.net/npm/mathjax@3/es5/tex-mml-chtml.js"></script>
    <script>DOCUMENTATION_OPTIONS.pagename = 'cost_functions';</script>
    <link rel="canonical" href="https://lisds.github.io/dsip/cost_functions.html" />
    <link rel="shortcut icon" href="_static/dsfe_favicon.ico"/>
    <link rel="index" title="Index" href="genindex.html" />
    <link rel="search" title="Search" href="search.html" />
    <link rel="next" title="Expressing the linear model with matrices" href="matrix_notation.html" />
    <link rel="prev" title="Multiple Logistic Regression, Model Selection and Cross-validation" href="logistic_regression_cross_validation.html" />
  <meta name="viewport" content="width=device-width, initial-scale=1"/>
  <meta name="docsearch:language" content="en"/>
  </head>
  
  
  <body data-bs-spy="scroll" data-bs-target=".bd-toc-nav" data-offset="180" data-bs-root-margin="0px 0px -60%" data-default-mode="">

  
  
  <a id="pst-skip-link" class="skip-link" href="#main-content">Skip to main content</a>
  
  <div id="pst-scroll-pixel-helper"></div>
  
  <button type="button" class="btn rounded-pill" id="pst-back-to-top">
    <i class="fa-solid fa-arrow-up"></i>
    Back to top
  </button>

  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__primary"
          id="__primary"/>
  <label class="overlay overlay-primary" for="__primary"></label>
  
  <input type="checkbox"
          class="sidebar-toggle"
          name="__secondary"
          id="__secondary"/>
  <label class="overlay overlay-secondary" for="__secondary"></label>
  
  <div class="search-button__wrapper">
    <div class="search-button__overlay"></div>
    <div class="search-button__search-container">
<form class="bd-search d-flex align-items-center"
      action="search.html"
      method="get">
  <i class="fa-solid fa-magnifying-glass"></i>
  <input type="search"
         class="form-control"
         name="q"
         id="search-input"
         placeholder="Search this book..."
         aria-label="Search this book..."
         autocomplete="off"
         autocorrect="off"
         autocapitalize="off"
         spellcheck="false"/>
  <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd>K</kbd></span>
</form></div>
  </div>
  
    <header class="bd-header navbar navbar-expand-lg bd-navbar">
    </header>
  

  <div class="bd-container">
    <div class="bd-container__inner bd-page-width">
      
      
      
      <div class="bd-sidebar-primary bd-sidebar">
        

  
  <div class="sidebar-header-items sidebar-primary__section">
    
    
    
    
  </div>
  
    <div class="sidebar-primary-items__start sidebar-primary__section">
        <div class="sidebar-primary-item">

  

<a class="navbar-brand logo" href="intro.html">
  
  
  
  
  
    
    
      
    
    
    <img src="_static/dsfe_logo.png" class="logo__image only-light" alt="Data Science in Practice - Home"/>
    <script>document.write(`<img src="_static/dsfe_logo.png" class="logo__image only-dark" alt="Data Science in Practice - Home"/>`);</script>
  
  
</a></div>
        <div class="sidebar-primary-item">

 <script>
 document.write(`
   <button class="btn navbar-btn search-button-field search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass"></i>
    <span class="search-button__default-text">Search</span>
    <span class="search-button__kbd-shortcut"><kbd class="kbd-shortcut__modifier">Ctrl</kbd>+<kbd class="kbd-shortcut__modifier">K</kbd></span>
   </button>
 `);
 </script></div>
        <div class="sidebar-primary-item"><nav class="bd-links bd-docs-nav" aria-label="Main">
    <div class="bd-toc-item navbar-nav active">
        <p aria-level="2" class="caption" role="heading"><span class="caption-text">Coding background</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="assert.html">Using <code class="docutils literal notranslate"><span class="pre">assert</span></code> for testing</a></li>
<li class="toctree-l1"><a class="reference internal" href="arrays_and_images.html">Arrays as images, images as arrays</a></li>
<li class="toctree-l1"><a class="reference internal" href="where_and_argmin.html">Where and argmin</a></li>
<li class="toctree-l1"><a class="reference internal" href="where_2d.html">Where in 2D</a></li>
<li class="toctree-l1"><a class="reference internal" href="image_for_optimize.html">2D arrays, images, optimization</a></li>
<li class="toctree-l1"><a class="reference internal" href="pathlib.html">Using the <code class="docutils literal notranslate"><span class="pre">pathlib</span></code> module</a></li>
<li class="toctree-l1"><a class="reference internal" href="dictionaries.html">Dictionaries</a></li>
<li class="toctree-l1"><a class="reference internal" href="pandas_and_dicts.html">Pandas and dictionaries</a></li>
<li class="toctree-l1"><a class="reference internal" href="lambda_functions.html">Lambda functions</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Reading formulae</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="on_vectors.html">Vectors and dot products</a></li>
<li class="toctree-l1"><a class="reference internal" href="numpy_and_vectors.html">Numpy, arrays, and vectors</a></li>
<li class="toctree-l1"><a class="reference internal" href="algebra_of_sums.html">Some algebra with summation</a></li>
<li class="toctree-l1"><a class="reference internal" href="lin_regression_notation.html">Notation for linear regression models</a></li>
<li class="toctree-l1"><a class="reference internal" href="vector_projection.html">Vector projection</a></li>
<li class="toctree-l1"><a class="reference internal" href="pca_introduction.html">Introducing principal component analysis</a></li>
<li class="toctree-l1"><a class="reference internal" href="pca_dimension_reduction.html">Dimension reduction with Principal Component Analysis</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Intermediate regression</span></p>
<ul class="current nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="lin_regression_multiple_predictors.html">Linear regression notation for models with multiple predictors</a></li>
<li class="toctree-l1"><a class="reference internal" href="epl_modeling.html">Attack or defense?  An example of multiple regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="linear_regression_categorical_predictors.html">Categorical predictors in linear regression</a></li>
<li class="toctree-l1"><a class="reference internal" href="multiple_predictors_statistical_adjustment.html">Statistical Adjustment in Multi-predictor Linear Regression Models</a></li>
<li class="toctree-l1"><a class="reference internal" href="logistic_regression_cross_validation.html">Multiple Logistic Regression, Model Selection and Cross-validation</a></li>
<li class="toctree-l1 current active"><a class="current reference internal" href="#">Fitting models with different cost functions</a></li>
<li class="toctree-l1"><a class="reference internal" href="matrix_notation.html">Expressing the linear model with matrices</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Classification</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="naive_bayes.html">Naive Bayes classifiers</a></li>
<li class="toctree-l1"><a class="reference internal" href="k_means.html">k-means clustering</a></li>
<li class="toctree-l1"><a class="reference internal" href="kernel_density_estimation.html">Kernel density estimation</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">Working with data</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="data_work.html">The problem with data</a></li>
</ul>
<p aria-level="2" class="caption" role="heading"><span class="caption-text">The tools</span></p>
<ul class="nav bd-sidenav">
<li class="toctree-l1"><a class="reference internal" href="installation.html">Installing on your computer</a></li>
<li class="toctree-l1"><a class="reference internal" href="the-problem-with-notebooks.html">The joys and sorrows of notebooks</a></li>
</ul>

    </div>
</nav></div>
    </div>
  
  
  <div class="sidebar-primary-items__end sidebar-primary__section">
  </div>
  
  <div id="rtd-footer-container"></div>


      </div>
      
      <main id="main-content" class="bd-main">
        
        

<div class="sbt-scroll-pixel-helper"></div>

          <div class="bd-content">
            <div class="bd-article-container">
              
              <div class="bd-header-article">
<div class="header-article-items header-article__inner">
  
    <div class="header-article-items__start">
      
        <div class="header-article-item"><label class="sidebar-toggle primary-toggle btn btn-sm" for="__primary" title="Toggle primary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
  <span class="fa-solid fa-bars"></span>
</label></div>
      
    </div>
  
  
    <div class="header-article-items__end">
      
        <div class="header-article-item">

<div class="article-header-buttons">





<div class="dropdown dropdown-launch-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Launch interactive content">
    <i class="fas fa-rocket"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://mybinder.org/v2/gh/lisds/dsip/main?urlpath=lab/tree/cost_functions.Rmd" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onBinder"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_binder.svg">
  </span>
<span class="btn__text-container">Binder</span>
</a>
</li>
      
      
      
      
      <li><a href="https://ds.lis.2i2c.cloud/hub/user-redirect/git-pull?repo=https%3A//github.com/lisds/dsip&urlpath=lab/tree/dsip/cost_functions.Rmd&branch=main" target="_blank"
   class="btn btn-sm dropdown-item"
   title="Launch onJupyterHub"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  
    <img src="_static/images/logo_jupyterhub.svg">
  </span>
<span class="btn__text-container">JupyterHub</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="initThebeSBT()"
  class="btn btn-sm btn-launch-thebe dropdown-item"
  title="Launch Thebe"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-play"></i>
  </span>
<span class="btn__text-container">Live Code</span>
</button>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-source-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Source repositories">
    <i class="fab fa-github"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="https://github.com/lisds/dsip" target="_blank"
   class="btn btn-sm btn-source-repository-button dropdown-item"
   title="Source repository"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fab fa-github"></i>
  </span>
<span class="btn__text-container">Repository</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/lisds/dsip/edit/main/cost_functions.Rmd" target="_blank"
   class="btn btn-sm btn-source-edit-button dropdown-item"
   title="Suggest edit"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-pencil-alt"></i>
  </span>
<span class="btn__text-container">Suggest edit</span>
</a>
</li>
      
      
      
      
      <li><a href="https://github.com/lisds/dsip/issues/new?title=Issue%20on%20page%20%2Fcost_functions.html&body=Your%20issue%20content%20here." target="_blank"
   class="btn btn-sm btn-source-issues-button dropdown-item"
   title="Open an issue"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-lightbulb"></i>
  </span>
<span class="btn__text-container">Open issue</span>
</a>
</li>
      
  </ul>
</div>






<div class="dropdown dropdown-download-buttons">
  <button class="btn dropdown-toggle" type="button" data-bs-toggle="dropdown" aria-expanded="false" aria-label="Download this page">
    <i class="fas fa-download"></i>
  </button>
  <ul class="dropdown-menu">
      
      
      
      <li><a href="_sources/cost_functions.Rmd" target="_blank"
   class="btn btn-sm btn-download-source-button dropdown-item"
   title="Download source file"
   data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file"></i>
  </span>
<span class="btn__text-container">.Rmd</span>
</a>
</li>
      
      
      
      
      <li>
<button onclick="window.print()"
  class="btn btn-sm btn-download-pdf-button dropdown-item"
  title="Print to PDF"
  data-bs-placement="left" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-file-pdf"></i>
  </span>
<span class="btn__text-container">.pdf</span>
</button>
</li>
      
  </ul>
</div>




<button onclick="toggleFullScreen()"
  class="btn btn-sm btn-fullscreen-button"
  title="Fullscreen mode"
  data-bs-placement="bottom" data-bs-toggle="tooltip"
>
  

<span class="btn__icon-container">
  <i class="fas fa-expand"></i>
  </span>

</button>



<script>
document.write(`
  <button class="btn btn-sm navbar-btn theme-switch-button" title="light/dark" aria-label="light/dark" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="theme-switch nav-link" data-mode="light"><i class="fa-solid fa-sun fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="dark"><i class="fa-solid fa-moon fa-lg"></i></span>
    <span class="theme-switch nav-link" data-mode="auto"><i class="fa-solid fa-circle-half-stroke fa-lg"></i></span>
  </button>
`);
</script>


<script>
document.write(`
  <button class="btn btn-sm navbar-btn search-button search-button__button" title="Search" aria-label="Search" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <i class="fa-solid fa-magnifying-glass fa-lg"></i>
  </button>
`);
</script>
<label class="sidebar-toggle secondary-toggle btn btn-sm" for="__secondary"title="Toggle secondary sidebar" data-bs-placement="bottom" data-bs-toggle="tooltip">
    <span class="fa-solid fa-list"></span>
</label>
</div></div>
      
    </div>
  
</div>
</div>
              
              

<div id="jb-print-docs-body" class="onlyprint">
    <h1>Fitting models with different cost functions</h1>
    <!-- Table of contents -->
    <div id="print-main-content">
        <div id="jb-print-toc">
            
            <div>
                <h2> Contents </h2>
            </div>
            <nav aria-label="Page">
                <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fitted-values-and-scikit-learn">The fitted values and Scikit-learn</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-short-diversion-writing-the-mean-in-symbols">A short diversion — writing the mean in symbols</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-long-and-the-short-of-r-2">The long and the short of <span class="math notranslate nohighlight">\(R^2\)</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#r-2-for-another-reduced-model"><span class="math notranslate nohighlight">\(R^2\)</span> for another, reduced model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#on-weights-and-a-weighted-mean">On weights, and a weighted mean</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-with-weights">Fitting with weights</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penalized-regression">Penalized regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-regression">Ridge regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso">LASSO</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">Cross-validation</a></li>
</ul>
            </nav>
        </div>
    </div>
</div>

              
                
<div id="searchbox"></div>
                <article class="bd-article">
                  
  <section class="tex2jax_ignore mathjax_ignore" id="fitting-models-with-different-cost-functions">
<h1>Fitting models with different cost functions<a class="headerlink" href="#fitting-models-with-different-cost-functions" title="Permalink to this heading">#</a></h1>
<p>We also get on to cross-validation.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="kn">import</span> <span class="nn">numpy</span> <span class="k">as</span> <span class="nn">np</span>
<span class="n">np</span><span class="o">.</span><span class="n">set_printoptions</span><span class="p">(</span><span class="n">suppress</span><span class="o">=</span><span class="kc">True</span><span class="p">)</span>
<span class="kn">from</span> <span class="nn">scipy.optimize</span> <span class="kn">import</span> <span class="n">minimize</span>
<span class="kn">import</span> <span class="nn">pandas</span> <span class="k">as</span> <span class="nn">pd</span>
<span class="n">pd</span><span class="o">.</span><span class="n">set_option</span><span class="p">(</span><span class="s1">&#39;mode.copy_on_write&#39;</span><span class="p">,</span> <span class="kc">True</span><span class="p">)</span>
<span class="kn">import</span> <span class="nn">statsmodels.formula.api</span> <span class="k">as</span> <span class="nn">smf</span>
<span class="kn">import</span> <span class="nn">sklearn.linear_model</span> <span class="k">as</span> <span class="nn">sklm</span>
<span class="kn">import</span> <span class="nn">sklearn.metrics</span> <span class="k">as</span> <span class="nn">skmetrics</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">df</span> <span class="o">=</span> <span class="n">pd</span><span class="o">.</span><span class="n">read_csv</span><span class="p">(</span><span class="s1">&#39;data/rate_my_course.csv&#39;</span><span class="p">)</span>
<span class="n">df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Discipline</th>
      <th>Number of Professors</th>
      <th>Clarity</th>
      <th>Helpfulness</th>
      <th>Overall Quality</th>
      <th>Easiness</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>English</td>
      <td>23343</td>
      <td>3.756147</td>
      <td>3.821866</td>
      <td>3.791364</td>
      <td>3.162754</td>
    </tr>
    <tr>
      <th>1</th>
      <td>Mathematics</td>
      <td>22394</td>
      <td>3.487379</td>
      <td>3.641526</td>
      <td>3.566867</td>
      <td>3.063322</td>
    </tr>
    <tr>
      <th>2</th>
      <td>Biology</td>
      <td>11774</td>
      <td>3.608331</td>
      <td>3.701530</td>
      <td>3.657641</td>
      <td>2.710459</td>
    </tr>
    <tr>
      <th>3</th>
      <td>Psychology</td>
      <td>11179</td>
      <td>3.909520</td>
      <td>3.887536</td>
      <td>3.900949</td>
      <td>3.316210</td>
    </tr>
    <tr>
      <th>4</th>
      <td>History</td>
      <td>11145</td>
      <td>3.788818</td>
      <td>3.753642</td>
      <td>3.773746</td>
      <td>3.053803</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>70</th>
      <td>Anatomy</td>
      <td>117</td>
      <td>3.932991</td>
      <td>3.974701</td>
      <td>3.954188</td>
      <td>2.863504</td>
    </tr>
    <tr>
      <th>71</th>
      <td>Earth Science</td>
      <td>110</td>
      <td>3.636182</td>
      <td>3.671364</td>
      <td>3.655091</td>
      <td>3.106727</td>
    </tr>
    <tr>
      <th>72</th>
      <td>Linguistics</td>
      <td>110</td>
      <td>3.749000</td>
      <td>3.834545</td>
      <td>3.798182</td>
      <td>3.309636</td>
    </tr>
    <tr>
      <th>73</th>
      <td>Mechanical Engineering</td>
      <td>104</td>
      <td>3.441923</td>
      <td>3.531154</td>
      <td>3.489327</td>
      <td>2.799135</td>
    </tr>
    <tr>
      <th>74</th>
      <td>Medicine</td>
      <td>102</td>
      <td>3.927255</td>
      <td>3.934216</td>
      <td>3.929118</td>
      <td>3.109118</td>
    </tr>
  </tbody>
</table>
<p>75 rows × 6 columns</p>
</div></div></div>
</div>
<p>Fetch some columns of interest:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># This will be our y (the variable we predict).</span>
<span class="n">helpfulness</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Helpfulness&#39;</span><span class="p">]</span>
<span class="c1"># One of both of these will be our X (the predictors).</span>
<span class="n">clarity_easiness</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Clarity&#39;</span><span class="p">,</span> <span class="s1">&#39;Easiness&#39;</span><span class="p">]]</span>
</pre></div>
</div>
</div>
</div>
<p>Fit the model with Statsmodels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">ols</span><span class="p">(</span><span class="s1">&#39;Helpfulness ~ Clarity + Easiness&#39;</span><span class="p">,</span> <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">sm_fit</span> <span class="o">=</span> <span class="n">sm_model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">sm_fit</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>OLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>Helpfulness</td>   <th>  R-squared:         </th> <td>   0.913</td>
</tr>
<tr>
  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.911</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   378.0</td>
</tr>
<tr>
  <th>Date:</th>             <td>Fri, 22 Mar 2024</td> <th>  Prob (F-statistic):</th> <td>6.53e-39</td>
</tr>
<tr>
  <th>Time:</th>                 <td>14:42:57</td>     <th>  Log-Likelihood:    </th> <td>  118.24</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    75</td>      <th>  AIC:               </th> <td>  -230.5</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    72</td>      <th>  BIC:               </th> <td>  -223.5</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    0.6342</td> <td>    0.116</td> <td>    5.483</td> <td> 0.000</td> <td>    0.404</td> <td>    0.865</td>
</tr>
<tr>
  <th>Clarity</th>   <td>    0.8477</td> <td>    0.047</td> <td>   18.160</td> <td> 0.000</td> <td>    0.755</td> <td>    0.941</td>
</tr>
<tr>
  <th>Easiness</th>  <td>   -0.0063</td> <td>    0.034</td> <td>   -0.183</td> <td> 0.855</td> <td>   -0.075</td> <td>    0.062</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td> 3.832</td> <th>  Durbin-Watson:     </th> <td>   1.847</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.147</td> <th>  Jarque-Bera (JB):  </th> <td>   3.429</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.524</td> <th>  Prob(JB):          </th> <td>   0.180</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 3.032</td> <th>  Cond. No.          </th> <td>    103.</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>Fit the same model with Scikit-learn.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sk_model</span> <span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span>
<span class="n">sk_fit</span> <span class="o">=</span> <span class="n">sk_model</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">clarity_easiness</span><span class="p">,</span> <span class="n">helpfulness</span><span class="p">)</span>
<span class="n">sk_fit</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-1 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-1 {
  color: var(--sklearn-color-text);
}

#sk-container-id-1 pre {
  padding: 0;
}

#sk-container-id-1 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-1 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-1 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-1 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-1 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-1 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-1 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-1 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-1 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-1 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-1 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-1 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-1 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-1 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-1 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-1 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-1 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-1 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-1 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-1 div.sk-label label.sk-toggleable__label,
#sk-container-id-1 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-1 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-1 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-1 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-1 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-1 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-1 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-1 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-1 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-1 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-1 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-1 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-1 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-1" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-1" type="checkbox" checked><label for="sk-estimator-id-1" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;LinearRegression<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html">?<span>Documentation for LinearRegression</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>LinearRegression()</pre></div> </div></div></div></div></div></div>
</div>
<p>The coefficients (the slopes for the regressors):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sk_fit</span><span class="o">.</span><span class="n">coef_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.84765719, -0.00628188])
</pre></div>
</div>
</div>
</div>
<p>The intercept:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sk_fit</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.6342163349072085
</pre></div>
</div>
</div>
</div>
<p>Compare the parameters to Statsmodels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm_fit</span><span class="o">.</span><span class="n">params</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Intercept    0.634216
Clarity      0.847657
Easiness    -0.006282
dtype: float64
</pre></div>
</div>
</div>
</div>
<section id="the-fitted-values-and-scikit-learn">
<h2>The fitted values and Scikit-learn<a class="headerlink" href="#the-fitted-values-and-scikit-learn" title="Permalink to this heading">#</a></h2>
<p>The values predicted by the (Sklearn) model:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y_hat</span> <span class="o">=</span> <span class="n">sk_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">clarity_easiness</span><span class="p">)</span>
<span class="n">y_hat</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([3.79827334, 3.57107499, 3.67581734, 3.92731675, 3.82665181,
       3.48871883, 3.89117061, 3.70003921, 3.8013664 , 3.48333495,
       3.69359333, 3.78395243, 3.47336086, 3.57017191, 3.81165212,
       3.59953202, 3.40917203, 3.74439846, 3.75529281, 3.87079006,
       3.71650243, 3.91081494, 3.84021344, 3.46140189, 4.05110024,
       3.69790129, 3.68125641, 3.73563421, 3.66975401, 3.76540619,
       3.77108961, 3.89775444, 3.81443707, 3.45401091, 3.71363585,
       3.84224058, 4.06748055, 3.80755826, 3.53711396, 3.7465973 ,
       3.68031767, 3.68119022, 3.88083408, 3.8323017 , 3.60821429,
       3.82505099, 3.69906336, 3.97423909, 3.96735067, 4.11466129,
       3.80967881, 3.60364526, 3.63462294, 3.68518199, 3.74639111,
       3.47842488, 3.76251001, 3.60481205, 3.93161439, 3.94669493,
       3.54215346, 3.96030499, 3.74421691, 3.81391267, 4.13556455,
       3.88432985, 3.80636234, 3.99835993, 3.84638216, 3.69029801,
       3.95005664, 3.69693593, 3.79129242, 3.53420337, 3.9436511 ])
</pre></div>
</div>
</div>
</div>
<p>Compare the fitted (<span class="math notranslate nohighlight">\(\hat{y}\)</span>) values to those from Statsmodels:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">()</span> <span class="o">-</span> <span class="n">y_hat</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0., 0.,
       0., 0., 0., 0., 0., 0., 0.])
</pre></div>
</div>
</div>
</div>
<p>Here’s a general check that the predictions are all the same (or close enough within computational precision):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">sm_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(),</span> <span class="n">y_hat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>We assemble Sklearn’s coefficients and intercept into a single list,
with the intercept last.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">params</span> <span class="o">=</span> <span class="nb">list</span><span class="p">(</span><span class="n">sk_fit</span><span class="o">.</span><span class="n">coef_</span><span class="p">)</span> <span class="o">+</span> <span class="p">[</span><span class="n">sk_fit</span><span class="o">.</span><span class="n">intercept_</span><span class="p">]</span>
<span class="n">params</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.8476571912478371, -0.006281876019590555, 0.6342163349072085]
</pre></div>
</div>
</div>
</div>
<p>If we just want all but the last parameter (all the coefficients, but not the intercept):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># All parameters but the last (all but the intercept parameter).</span>
<span class="n">params</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>[0.8476571912478371, -0.006281876019590555]
</pre></div>
</div>
</div>
</div>
<p>We could also get the parameters from Statsmodels, but we’d have to rearrange them, because Statsmodels puts the intercept first rather than last:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm_fit</span><span class="o">.</span><span class="n">params</span><span class="o">.</span><span class="n">iloc</span><span class="p">[[</span><span class="mi">1</span><span class="p">,</span> <span class="mi">2</span><span class="p">,</span> <span class="mi">0</span><span class="p">]]</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>Clarity      0.847657
Easiness    -0.006282
Intercept    0.634216
dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Write a function to compute the fitted values given the parameters:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">calc_fitted</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Calculate fitted values from design X and parameters</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    params : vector (1D array)</span>
<span class="sd">        Vector of parameters, intercept is last parameter.</span>
<span class="sd">    X : array</span>
<span class="sd">        2D array with regressor columns.</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    y_hat : vector</span>
<span class="sd">        Vector of fitted values</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">X</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">array</span><span class="p">(</span><span class="n">X</span><span class="p">)</span>
    <span class="n">n</span><span class="p">,</span> <span class="n">p</span> <span class="o">=</span> <span class="n">X</span><span class="o">.</span><span class="n">shape</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">zeros</span><span class="p">(</span><span class="n">n</span><span class="p">)</span>
    <span class="k">for</span> <span class="n">col_no</span><span class="p">,</span> <span class="n">param</span> <span class="ow">in</span> <span class="nb">enumerate</span><span class="p">(</span><span class="n">params</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]):</span>
        <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span> <span class="o">+</span> <span class="n">param</span> <span class="o">*</span> <span class="n">X</span><span class="p">[:,</span> <span class="n">col_no</span><span class="p">]</span>  <span class="c1"># Add contribution from this regressor.</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">y_hat</span> <span class="o">+</span> <span class="n">params</span><span class="p">[</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span>  <span class="c1"># Add contribution from intercept.</span>
    <span class="k">return</span> <span class="n">y_hat</span>
</pre></div>
</div>
</div>
</div>
<p>Show that we get the same fitted values from our function as we got from
the <code class="docutils literal notranslate"><span class="pre">predict</span></code> method of Sklearn:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">our_y_hat</span> <span class="o">=</span> <span class="n">calc_fitted</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">clarity_easiness</span><span class="p">)</span>
<span class="k">assert</span> <span class="n">np</span><span class="o">.</span><span class="n">allclose</span><span class="p">(</span><span class="n">our_y_hat</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Calculate the error vector and then calculate the sum of squared error:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">e</span> <span class="o">=</span> <span class="n">helpfulness</span> <span class="o">-</span> <span class="n">our_y_hat</span>
<span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">e</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.18759984412745978
</pre></div>
</div>
</div>
</div>
<p>Make a function to calculate sum of squared error:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sos</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Sum of squared error for `params` given model `X` and data `y`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">calc_fitted</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span>  <span class="c1"># residuals</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">e</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Check that we get the same answer from the function as we got from
calculating above:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sos</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">clarity_easiness</span><span class="p">,</span> <span class="n">helpfulness</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.18759984412745978
</pre></div>
</div>
</div>
</div>
<p>Use <code class="docutils literal notranslate"><span class="pre">minimize</span></code> to find parameters minimizing the sum of squared error:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">min_res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">sos</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">clarity_easiness</span><span class="p">,</span> <span class="n">helpfulness</span><span class="p">))</span>
<span class="n">min_res</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  message: Optimization terminated successfully.
  success: True
   status: 0
      fun: 0.18759984414069664
        x: [ 8.477e-01 -6.281e-03  6.342e-01]
      nit: 8
      jac: [ 3.278e-07  2.831e-07  1.155e-07]
 hess_inv: [[ 4.169e-01 -2.313e-01 -8.092e-01]
            [-2.313e-01  2.249e-01  1.414e-01]
            [-8.092e-01  1.414e-01  2.557e+00]]
     nfev: 40
     njev: 10
</pre></div>
</div>
</div>
</div>
<p>Yes, the parameters (coefficients and intercept) are the same as we got
from Statsmodels and Sklearn:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">min_res</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([ 0.84765427, -0.00628103,  0.63422445])
</pre></div>
</div>
</div>
</div>
</section>
<section id="a-short-diversion-writing-the-mean-in-symbols">
<h2>A short diversion — writing the mean in symbols<a class="headerlink" href="#a-short-diversion-writing-the-mean-in-symbols" title="Permalink to this heading">#</a></h2>
<p>For notational convenience, give our <code class="docutils literal notranslate"><span class="pre">y</span></code> (“Helpfulness”) vector the
variable name <code class="docutils literal notranslate"><span class="pre">y</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">y</span> <span class="o">=</span> <span class="n">helpfulness</span>
</pre></div>
</div>
</div>
</div>
<p>This is the usual mean, on <code class="docutils literal notranslate"><span class="pre">y</span></code> (the ‘Helpfulness” scores):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.758165438295424
</pre></div>
</div>
</div>
</div>
<p>The calculation is:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
<span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.758165438295424
</pre></div>
</div>
</div>
</div>
<p>Of course this is the same as:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="o">/</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.758165438295424
</pre></div>
</div>
</div>
</div>
<p>In mathematical notation, we write this as:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
\bar{y} = \frac{1}{n} (y_1 + y_2 + ... + y_n) \\
\end{split}\]</div>
<p>where <span class="math notranslate nohighlight">\(\bar{y}\)</span> is the mean of the values in the vector <span class="math notranslate nohighlight">\(\vec{y}\)</span>.</p>
<p>We could also write the operation of adding up the <span class="math notranslate nohighlight">\(y\)</span> values with the
<span class="math notranslate nohighlight">\(\sum\)</span> notation:</p>
<div class="math notranslate nohighlight">
\[
\sum_i y_i = (y_1 + y_2 + ... + y_n)
\]</div>
<p>Using the <span class="math notranslate nohighlight">\(\sum\)</span> notation, we write the mean as:</p>
<div class="math notranslate nohighlight">
\[
\bar{y} = \frac{1}{n} \sum_i y_i
\]</div>
<p>This notation is very similar to the equivalent code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="o">/</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.758165438295424
</pre></div>
</div>
</div>
</div>
</section>
<section id="the-long-and-the-short-of-r-2">
<h2>The long and the short of <span class="math notranslate nohighlight">\(R^2\)</span><a class="headerlink" href="#the-long-and-the-short-of-r-2" title="Permalink to this heading">#</a></h2>
<p><span class="math notranslate nohighlight">\(R^2\)</span> can also be called the <a class="reference external" href="https://en.wikipedia.org/wiki/Coefficient_of_determination">coefficient of
determination</a>.</p>
<p>Sklearn has an <code class="docutils literal notranslate"><span class="pre">r2_score</span></code> metric.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">skmetrics</span><span class="o">.</span><span class="n">r2_score</span><span class="p">(</span><span class="n">helpfulness</span><span class="p">,</span> <span class="n">y_hat</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9130445684300285
</pre></div>
</div>
</div>
</div>
<p>The Statsmodels <code class="docutils literal notranslate"><span class="pre">fit</span></code> object has an <code class="docutils literal notranslate"><span class="pre">rsquared</span></code> attribute with the <span class="math notranslate nohighlight">\(R^2\)</span> value:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm_fit</span><span class="o">.</span><span class="n">rsquared</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9130445684300286
</pre></div>
</div>
</div>
</div>
<p>The formula for <span class="math notranslate nohighlight">\(R^2\)</span> is:</p>
<div class="math notranslate nohighlight">
\[
R^2 = 1 - {SS_{\rm resid}\over SS_{\rm total}}
\]</div>
<p>If <span class="math notranslate nohighlight">\(\hat{y}_i\)</span> is the <em>fitted</em>
value for observation <span class="math notranslate nohighlight">\(i\)</span>, then the residual error <span class="math notranslate nohighlight">\(e_i\)</span> for observation
<span class="math notranslate nohighlight">\(i\)</span> is <span class="math notranslate nohighlight">\(y_i - \hat{y}_i\)</span>, and <span class="math notranslate nohighlight">\(SS_{\text{resid}}\)</span> is the sum of
squares of the residuals:</p>
<div class="math notranslate nohighlight">
\[
SS_\text{resid}=\sum_i (y_i - \hat{y}_i)^2=\sum_i e_i^2\
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ss_resid</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ss_resid</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.18759984412745978
</pre></div>
</div>
</div>
</div>
<p>As you saw above, we write the mean of the observed values <span class="math notranslate nohighlight">\(y\)</span> as <span class="math notranslate nohighlight">\(\bar{y}\)</span>.</p>
<p>The denominator for the standard <span class="math notranslate nohighlight">\(R^2\)</span> statistic is the “total sum of squares” <span class="math notranslate nohighlight">\(SS_\text{tot}\)</span>, written as:</p>
<div class="math notranslate nohighlight">
\[
SS_\text{total}=\sum_i (y_i - \bar{y})^2
\]</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">ss_total</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">y</span> <span class="o">-</span> <span class="n">np</span><span class="o">.</span><span class="n">mean</span><span class="p">(</span><span class="n">y</span><span class="p">))</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">ss_total</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>2.157425254988258
</pre></div>
</div>
</div>
</div>
<p>We can calculate <span class="math notranslate nohighlight">\(R^2\)</span> by hand to show this gives the same answer as Sklearn and Statsmodels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Calculate R2</span>
<span class="mi">1</span> <span class="o">-</span> <span class="n">ss_resid</span> <span class="o">/</span> <span class="n">ss_total</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9130445684300285
</pre></div>
</div>
</div>
</div>
<p>The by-hand calculation gives the same answer as Sklearn or Statsmodels.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm_fit</span><span class="o">.</span><span class="n">rsquared</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.9130445684300286
</pre></div>
</div>
</div>
</div>
<section id="r-2-for-another-reduced-model">
<h3><span class="math notranslate nohighlight">\(R^2\)</span> for another, reduced model<a class="headerlink" href="#r-2-for-another-reduced-model" title="Permalink to this heading">#</a></h3>
<p>You can think of the standard <span class="math notranslate nohighlight">\(R^2\)</span> above as a measure of the improvement in fit for an expanded model (with the regressors included) compared to a reduced model (that only uses the mean).</p>
<p>You can use the same idea to compare an expanded model to another reduced model.</p>
<p>For example, we can fit a reduced model that is just “Clarity” without “Easiness”.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">clarity_df</span> <span class="o">=</span> <span class="n">df</span><span class="p">[[</span><span class="s1">&#39;Clarity&#39;</span><span class="p">]]</span>
<span class="n">reduced_fit</span> <span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">clarity_df</span><span class="p">,</span> <span class="n">helpfulness</span><span class="p">)</span>
<span class="n">reduced_fit</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">reduced_fit</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([0.84119015]), 0.6381903166650691)
</pre></div>
</div>
</div>
</div>
<p>Calculate <span class="math notranslate nohighlight">\(R^2\)</span> for reduced model as compared to our full model.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">reduced_resid</span> <span class="o">=</span> <span class="n">helpfulness</span> <span class="o">-</span> <span class="n">reduced_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">clarity_df</span><span class="p">)</span>
<span class="n">ss_reduced_resid</span> <span class="o">=</span> <span class="p">(</span><span class="n">reduced_resid</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span><span class="o">.</span><span class="n">sum</span><span class="p">()</span>
<span class="n">ss_reduced_resid</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.18768752586074872
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="o">-</span> <span class="n">ss_resid</span> <span class="o">/</span> <span class="n">ss_reduced_resid</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.0004671686777627526
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="on-weights-and-a-weighted-mean">
<h2>On weights, and a weighted mean<a class="headerlink" href="#on-weights-and-a-weighted-mean" title="Permalink to this heading">#</a></h2>
<p>You remember, from the discussion of the mean, above, that we can write
the mean calculation as:</p>
<div class="math notranslate nohighlight">
\[
\bar{y} = \frac{1}{n} \sum_i y_i
\]</div>
<p>In code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="mi">1</span> <span class="o">/</span> <span class="n">n</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.758165438295424
</pre></div>
</div>
</div>
</div>
<p>Mathematically, because <span class="math notranslate nohighlight">\(p * (q + r) = p * q + p * r\)</span> (the <a class="reference external" href="https://en.wikipedia.org/wiki/Distributive_property">distributive
property</a> of
multiplication), we can also do the multiplication by <span class="math notranslate nohighlight">\(\frac{1}{n}\)</span> <em>inside
the brackets</em>, like this:</p>
<div class="math notranslate nohighlight">
\[
\bar{y} = \frac{1}{n} y_1 +
          \frac{1}{n} y_2 +
          ...
          \frac{1}{n} y_n
\]</div>
<p>With the <span class="math notranslate nohighlight">\(\sum\)</span> notation, that would be:</p>
<div class="math notranslate nohighlight">
\[
\bar{y} = \sum_i \frac{1}{n} y_i
\]</div>
<p>In code:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="mi">1</span> <span class="o">/</span> <span class="n">n</span> <span class="o">*</span> <span class="n">y</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.7581654382954235
</pre></div>
</div>
</div>
</div>
<p>Think of this - the standard calculation of the mean - as giving each value in
<span class="math notranslate nohighlight">\(y\)</span> the same <em>weight</em> - of <span class="math notranslate nohighlight">\(\frac{1}{n}\)</span>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weights</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">ones</span><span class="p">(</span><span class="n">n</span><span class="p">)</span> <span class="o">/</span> <span class="n">n</span>
<span class="n">weights</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333,
       0.01333333, 0.01333333, 0.01333333, 0.01333333, 0.01333333])
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.7581654382954235
</pre></div>
</div>
</div>
</div>
<p>We can calculate weights to weight each “Helpfulness” value by the number of
professors.  Maybe we would do this on the basis that larger number of
professors may give more reliable values, and should therefore contribute
relatively more to the mean.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">n_professors</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Number of Professors&#39;</span><span class="p">]</span>
<span class="n">n_professors</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     23343
1     22394
2     11774
3     11179
4     11145
      ...  
70      117
71      110
72      110
73      104
74      102
Name: Number of Professors, Length: 75, dtype: int64
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">total_n_professors</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">n_professors</span><span class="p">)</span>
<span class="n">total_n_professors</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>183894
</pre></div>
</div>
</div>
</div>
<p>Calculate the proportion of professors represented by each discipline:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">prop_professors_by_subject</span> <span class="o">=</span> <span class="n">n_professors</span> <span class="o">/</span> <span class="n">total_n_professors</span>
<span class="n">prop_professors_by_subject</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     0.126937
1     0.121777
2     0.064026
3     0.060790
4     0.060606
        ...   
70    0.000636
71    0.000598
72    0.000598
73    0.000566
74    0.000555
Name: Number of Professors, Length: 75, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Now we have divided each value by the sum of the values, to give the
proportions, the proportions must add up to 1:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">prop_professors_by_subject</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>1.0
</pre></div>
</div>
</div>
</div>
<p>Calculate weighted mean, where the weights are the proportions of professors in the matching discipline:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Weighted mean of helpfulness (y), weighted by number of professors.</span>
<span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">y</span> <span class="o">*</span> <span class="n">prop_professors_by_subject</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.7234004372083844
</pre></div>
</div>
</div>
</div>
<p>Numpy’s version of same:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">prop_professors_by_subject</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.7234004372083844
</pre></div>
</div>
</div>
</div>
<p>And in fact, Numpy will check whether the weights sum to 1, and if not, will automatically divide the weights by their sum, so we can get the same calculation with the raw numbers of professors:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">np</span><span class="o">.</span><span class="n">average</span><span class="p">(</span><span class="n">y</span><span class="p">,</span> <span class="n">weights</span><span class="o">=</span><span class="n">n_professors</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.723400437208384
</pre></div>
</div>
</div>
</div>
</section>
<section id="fitting-with-weights">
<h2>Fitting with weights<a class="headerlink" href="#fitting-with-weights" title="Permalink to this heading">#</a></h2>
<p>Weighted regression differs from standard regression, only in weighting each
<em>squared residual</em> <span class="math notranslate nohighlight">\(e^2_i = (y_i - \hat{y_i})^2\)</span> by some weight for that
observation — call this <span class="math notranslate nohighlight">\(w_i\)</span>.</p>
<p>As we saw above in standard regression — AKA “ordinary least squares”
regression, the cost function is the sum of squares of the residuals
(<span class="math notranslate nohighlight">\(SS_{resid}\)</span>):</p>
<div class="math notranslate nohighlight">
\[\begin{split}
SS_\text{resid}=\sum_i (y_i - \hat{y}_i)^2 \\
=\sum_i e_i^2
\end{split}\]</div>
<p>In weighted regression we have a weight <span class="math notranslate nohighlight">\(w_i\)</span> for each observation, and the cost function is:</p>
<div class="math notranslate nohighlight">
\[\begin{split}
SS_\text{weighted_resid}=\sum_i w_i (y_i - \hat{y}_i)^2 \\
=\sum_i w_i  e_i^2
\end{split}\]</div>
<p>Also see <a class="reference external" href="https://en.wikipedia.org/wiki/Weighted_least_squares">Wikipedia on weighted
regression</a>.</p>
<p>First we show weighted regression in action, and then show how this cost function works in code, with <code class="docutils literal notranslate"><span class="pre">minimize</span></code>.</p>
<p>Here we use Statsmodels to do weighted regression.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sm_weighted_model</span> <span class="o">=</span> <span class="n">smf</span><span class="o">.</span><span class="n">wls</span><span class="p">(</span><span class="s1">&#39;Helpfulness ~ Clarity + Easiness&#39;</span><span class="p">,</span>
                            <span class="n">weights</span><span class="o">=</span><span class="n">prop_professors_by_subject</span><span class="p">,</span>
                            <span class="n">data</span><span class="o">=</span><span class="n">df</span><span class="p">)</span>
<span class="n">sm_weighted_fit</span> <span class="o">=</span> <span class="n">sm_weighted_model</span><span class="o">.</span><span class="n">fit</span><span class="p">()</span>
<span class="n">sm_weighted_fit</span><span class="o">.</span><span class="n">summary</span><span class="p">()</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><table class="simpletable">
<caption>WLS Regression Results</caption>
<tr>
  <th>Dep. Variable:</th>       <td>Helpfulness</td>   <th>  R-squared:         </th> <td>   0.898</td>
</tr>
<tr>
  <th>Model:</th>                   <td>WLS</td>       <th>  Adj. R-squared:    </th> <td>   0.895</td>
</tr>
<tr>
  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   316.8</td>
</tr>
<tr>
  <th>Date:</th>             <td>Fri, 22 Mar 2024</td> <th>  Prob (F-statistic):</th> <td>2.06e-36</td>
</tr>
<tr>
  <th>Time:</th>                 <td>14:42:57</td>     <th>  Log-Likelihood:    </th> <td>  90.990</td>
</tr>
<tr>
  <th>No. Observations:</th>      <td>    75</td>      <th>  AIC:               </th> <td>  -176.0</td>
</tr>
<tr>
  <th>Df Residuals:</th>          <td>    72</td>      <th>  BIC:               </th> <td>  -169.0</td>
</tr>
<tr>
  <th>Df Model:</th>              <td>     2</td>      <th>                     </th>     <td> </td>   
</tr>
<tr>
  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>   
</tr>
</table>
<table class="simpletable">
<tr>
      <td></td>         <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  
</tr>
<tr>
  <th>Intercept</th> <td>    1.0847</td> <td>    0.105</td> <td>   10.293</td> <td> 0.000</td> <td>    0.875</td> <td>    1.295</td>
</tr>
<tr>
  <th>Clarity</th>   <td>    0.7139</td> <td>    0.041</td> <td>   17.596</td> <td> 0.000</td> <td>    0.633</td> <td>    0.795</td>
</tr>
<tr>
  <th>Easiness</th>  <td>    0.0080</td> <td>    0.031</td> <td>    0.257</td> <td> 0.798</td> <td>   -0.054</td> <td>    0.070</td>
</tr>
</table>
<table class="simpletable">
<tr>
  <th>Omnibus:</th>       <td>13.040</td> <th>  Durbin-Watson:     </th> <td>   1.729</td>
</tr>
<tr>
  <th>Prob(Omnibus):</th> <td> 0.001</td> <th>  Jarque-Bera (JB):  </th> <td>  21.801</td>
</tr>
<tr>
  <th>Skew:</th>          <td> 0.619</td> <th>  Prob(JB):          </th> <td>1.84e-05</td>
</tr>
<tr>
  <th>Kurtosis:</th>      <td> 5.333</td> <th>  Cond. No.          </th> <td>    108.</td>
</tr>
</table><br/><br/>Notes:<br/>[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.</div></div>
</div>
<p>To save some typing, and for notational convenience in code, call our
two-regressor design <code class="docutils literal notranslate"><span class="pre">X</span></code>:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">X</span> <span class="o">=</span> <span class="n">clarity_easiness</span>
<span class="n">X</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Clarity</th>
      <th>Easiness</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.756147</td>
      <td>3.162754</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3.487379</td>
      <td>3.063322</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.608331</td>
      <td>2.710459</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.909520</td>
      <td>3.316210</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3.788818</td>
      <td>3.053803</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>70</th>
      <td>3.932991</td>
      <td>2.863504</td>
    </tr>
    <tr>
      <th>71</th>
      <td>3.636182</td>
      <td>3.106727</td>
    </tr>
    <tr>
      <th>72</th>
      <td>3.749000</td>
      <td>3.309636</td>
    </tr>
    <tr>
      <th>73</th>
      <td>3.441923</td>
      <td>2.799135</td>
    </tr>
    <tr>
      <th>74</th>
      <td>3.927255</td>
      <td>3.109118</td>
    </tr>
  </tbody>
</table>
<p>75 rows × 2 columns</p>
</div></div></div>
</div>
<p>You can also do <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.LinearRegression.html">weighted regression in
Sklearn</a>, by passing weights to the <code class="docutils literal notranslate"><span class="pre">LinearRegression</span></code> <code class="docutils literal notranslate"><span class="pre">fit</span></code> method:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sk_weighted</span> <span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">X</span><span class="p">,</span>  <span class="c1"># clarity_easiness</span>
    <span class="n">y</span><span class="p">,</span>  <span class="c1"># Helpfulness</span>
    <span class="n">sample_weight</span><span class="o">=</span><span class="n">prop_professors_by_subject</span><span class="p">)</span>
<span class="n">sk_weighted</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><style>#sk-container-id-2 {
  /* Definition of color scheme common for light and dark mode */
  --sklearn-color-text: black;
  --sklearn-color-line: gray;
  /* Definition of color scheme for unfitted estimators */
  --sklearn-color-unfitted-level-0: #fff5e6;
  --sklearn-color-unfitted-level-1: #f6e4d2;
  --sklearn-color-unfitted-level-2: #ffe0b3;
  --sklearn-color-unfitted-level-3: chocolate;
  /* Definition of color scheme for fitted estimators */
  --sklearn-color-fitted-level-0: #f0f8ff;
  --sklearn-color-fitted-level-1: #d4ebff;
  --sklearn-color-fitted-level-2: #b3dbfd;
  --sklearn-color-fitted-level-3: cornflowerblue;

  /* Specific color for light theme */
  --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, white)));
  --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, black)));
  --sklearn-color-icon: #696969;

  @media (prefers-color-scheme: dark) {
    /* Redefinition of color scheme for dark theme */
    --sklearn-color-text-on-default-background: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-background: var(--sg-background-color, var(--theme-background, var(--jp-layout-color0, #111)));
    --sklearn-color-border-box: var(--sg-text-color, var(--theme-code-foreground, var(--jp-content-font-color1, white)));
    --sklearn-color-icon: #878787;
  }
}

#sk-container-id-2 {
  color: var(--sklearn-color-text);
}

#sk-container-id-2 pre {
  padding: 0;
}

#sk-container-id-2 input.sk-hidden--visually {
  border: 0;
  clip: rect(1px 1px 1px 1px);
  clip: rect(1px, 1px, 1px, 1px);
  height: 1px;
  margin: -1px;
  overflow: hidden;
  padding: 0;
  position: absolute;
  width: 1px;
}

#sk-container-id-2 div.sk-dashed-wrapped {
  border: 1px dashed var(--sklearn-color-line);
  margin: 0 0.4em 0.5em 0.4em;
  box-sizing: border-box;
  padding-bottom: 0.4em;
  background-color: var(--sklearn-color-background);
}

#sk-container-id-2 div.sk-container {
  /* jupyter's `normalize.less` sets `[hidden] { display: none; }`
     but bootstrap.min.css set `[hidden] { display: none !important; }`
     so we also need the `!important` here to be able to override the
     default hidden behavior on the sphinx rendered scikit-learn.org.
     See: https://github.com/scikit-learn/scikit-learn/issues/21755 */
  display: inline-block !important;
  position: relative;
}

#sk-container-id-2 div.sk-text-repr-fallback {
  display: none;
}

div.sk-parallel-item,
div.sk-serial,
div.sk-item {
  /* draw centered vertical line to link estimators */
  background-image: linear-gradient(var(--sklearn-color-text-on-default-background), var(--sklearn-color-text-on-default-background));
  background-size: 2px 100%;
  background-repeat: no-repeat;
  background-position: center center;
}

/* Parallel-specific style estimator block */

#sk-container-id-2 div.sk-parallel-item::after {
  content: "";
  width: 100%;
  border-bottom: 2px solid var(--sklearn-color-text-on-default-background);
  flex-grow: 1;
}

#sk-container-id-2 div.sk-parallel {
  display: flex;
  align-items: stretch;
  justify-content: center;
  background-color: var(--sklearn-color-background);
  position: relative;
}

#sk-container-id-2 div.sk-parallel-item {
  display: flex;
  flex-direction: column;
}

#sk-container-id-2 div.sk-parallel-item:first-child::after {
  align-self: flex-end;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:last-child::after {
  align-self: flex-start;
  width: 50%;
}

#sk-container-id-2 div.sk-parallel-item:only-child::after {
  width: 0;
}

/* Serial-specific style estimator block */

#sk-container-id-2 div.sk-serial {
  display: flex;
  flex-direction: column;
  align-items: center;
  background-color: var(--sklearn-color-background);
  padding-right: 1em;
  padding-left: 1em;
}


/* Toggleable style: style used for estimator/Pipeline/ColumnTransformer box that is
clickable and can be expanded/collapsed.
- Pipeline and ColumnTransformer use this feature and define the default style
- Estimators will overwrite some part of the style using the `sk-estimator` class
*/

/* Pipeline and ColumnTransformer style (default) */

#sk-container-id-2 div.sk-toggleable {
  /* Default theme specific background. It is overwritten whether we have a
  specific estimator or a Pipeline/ColumnTransformer */
  background-color: var(--sklearn-color-background);
}

/* Toggleable label */
#sk-container-id-2 label.sk-toggleable__label {
  cursor: pointer;
  display: block;
  width: 100%;
  margin-bottom: 0;
  padding: 0.5em;
  box-sizing: border-box;
  text-align: center;
}

#sk-container-id-2 label.sk-toggleable__label-arrow:before {
  /* Arrow on the left of the label */
  content: "▸";
  float: left;
  margin-right: 0.25em;
  color: var(--sklearn-color-icon);
}

#sk-container-id-2 label.sk-toggleable__label-arrow:hover:before {
  color: var(--sklearn-color-text);
}

/* Toggleable content - dropdown */

#sk-container-id-2 div.sk-toggleable__content {
  max-height: 0;
  max-width: 0;
  overflow: hidden;
  text-align: left;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content pre {
  margin: 0.2em;
  border-radius: 0.25em;
  color: var(--sklearn-color-text);
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-toggleable__content.fitted pre {
  /* unfitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

#sk-container-id-2 input.sk-toggleable__control:checked~div.sk-toggleable__content {
  /* Expand drop-down */
  max-height: 200px;
  max-width: 100%;
  overflow: auto;
}

#sk-container-id-2 input.sk-toggleable__control:checked~label.sk-toggleable__label-arrow:before {
  content: "▾";
}

/* Pipeline/ColumnTransformer-specific style */

#sk-container-id-2 div.sk-label input.sk-toggleable__control:checked~label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-label.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator-specific style */

/* Colorize estimator box */
#sk-container-id-2 div.sk-estimator input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted input.sk-toggleable__control:checked~label.sk-toggleable__label {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

#sk-container-id-2 div.sk-label label.sk-toggleable__label,
#sk-container-id-2 div.sk-label label {
  /* The background is the default theme color */
  color: var(--sklearn-color-text-on-default-background);
}

/* On hover, darken the color of the background */
#sk-container-id-2 div.sk-label:hover label.sk-toggleable__label {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-unfitted-level-2);
}

/* Label box, darken color on hover, fitted */
#sk-container-id-2 div.sk-label.fitted:hover label.sk-toggleable__label.fitted {
  color: var(--sklearn-color-text);
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Estimator label */

#sk-container-id-2 div.sk-label label {
  font-family: monospace;
  font-weight: bold;
  display: inline-block;
  line-height: 1.2em;
}

#sk-container-id-2 div.sk-label-container {
  text-align: center;
}

/* Estimator-specific */
#sk-container-id-2 div.sk-estimator {
  font-family: monospace;
  border: 1px dotted var(--sklearn-color-border-box);
  border-radius: 0.25em;
  box-sizing: border-box;
  margin-bottom: 0.5em;
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-0);
}

#sk-container-id-2 div.sk-estimator.fitted {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-0);
}

/* on hover */
#sk-container-id-2 div.sk-estimator:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-2);
}

#sk-container-id-2 div.sk-estimator.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-2);
}

/* Specification for estimator info (e.g. "i" and "?") */

/* Common style for "i" and "?" */

.sk-estimator-doc-link,
a:link.sk-estimator-doc-link,
a:visited.sk-estimator-doc-link {
  float: right;
  font-size: smaller;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1em;
  height: 1em;
  width: 1em;
  text-decoration: none !important;
  margin-left: 1ex;
  /* unfitted */
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
  color: var(--sklearn-color-unfitted-level-1);
}

.sk-estimator-doc-link.fitted,
a:link.sk-estimator-doc-link.fitted,
a:visited.sk-estimator-doc-link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
div.sk-estimator:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover,
div.sk-label-container:hover .sk-estimator-doc-link:hover,
.sk-estimator-doc-link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

div.sk-estimator.fitted:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover,
div.sk-label-container:hover .sk-estimator-doc-link.fitted:hover,
.sk-estimator-doc-link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

/* Span, style for the box shown on hovering the info icon */
.sk-estimator-doc-link span {
  display: none;
  z-index: 9999;
  position: relative;
  font-weight: normal;
  right: .2ex;
  padding: .5ex;
  margin: .5ex;
  width: min-content;
  min-width: 20ex;
  max-width: 50ex;
  color: var(--sklearn-color-text);
  box-shadow: 2pt 2pt 4pt #999;
  /* unfitted */
  background: var(--sklearn-color-unfitted-level-0);
  border: .5pt solid var(--sklearn-color-unfitted-level-3);
}

.sk-estimator-doc-link.fitted span {
  /* fitted */
  background: var(--sklearn-color-fitted-level-0);
  border: var(--sklearn-color-fitted-level-3);
}

.sk-estimator-doc-link:hover span {
  display: block;
}

/* "?"-specific style due to the `<a>` HTML tag */

#sk-container-id-2 a.estimator_doc_link {
  float: right;
  font-size: 1rem;
  line-height: 1em;
  font-family: monospace;
  background-color: var(--sklearn-color-background);
  border-radius: 1rem;
  height: 1rem;
  width: 1rem;
  text-decoration: none;
  /* unfitted */
  color: var(--sklearn-color-unfitted-level-1);
  border: var(--sklearn-color-unfitted-level-1) 1pt solid;
}

#sk-container-id-2 a.estimator_doc_link.fitted {
  /* fitted */
  border: var(--sklearn-color-fitted-level-1) 1pt solid;
  color: var(--sklearn-color-fitted-level-1);
}

/* On hover */
#sk-container-id-2 a.estimator_doc_link:hover {
  /* unfitted */
  background-color: var(--sklearn-color-unfitted-level-3);
  color: var(--sklearn-color-background);
  text-decoration: none;
}

#sk-container-id-2 a.estimator_doc_link.fitted:hover {
  /* fitted */
  background-color: var(--sklearn-color-fitted-level-3);
}
</style><div id="sk-container-id-2" class="sk-top-container"><div class="sk-text-repr-fallback"><pre>LinearRegression()</pre><b>In a Jupyter environment, please rerun this cell to show the HTML representation or trust the notebook. <br />On GitHub, the HTML representation is unable to render, please try loading this page with nbviewer.org.</b></div><div class="sk-container" hidden><div class="sk-item"><div class="sk-estimator fitted sk-toggleable"><input class="sk-toggleable__control sk-hidden--visually" id="sk-estimator-id-2" type="checkbox" checked><label for="sk-estimator-id-2" class="sk-toggleable__label fitted sk-toggleable__label-arrow fitted">&nbsp;&nbsp;LinearRegression<a class="sk-estimator-doc-link fitted" rel="noreferrer" target="_blank" href="https://scikit-learn.org/1.4/modules/generated/sklearn.linear_model.LinearRegression.html">?<span>Documentation for LinearRegression</span></a><span class="sk-estimator-doc-link fitted">i<span>Fitted</span></span></label><div class="sk-toggleable__content fitted"><pre>LinearRegression()</pre></div> </div></div></div></div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sk_weighted</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">sk_weighted</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([0.7138681 , 0.00799134]), 1.0846520953764385)
</pre></div>
</div>
</div>
</div>
<p>The <code class="docutils literal notranslate"><span class="pre">minimize</span></code> cost function for weighted regression:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sos_weighted</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">weights</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Weighted least squares cost function</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">y_hat</span> <span class="o">=</span> <span class="n">calc_fitted</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">)</span>
    <span class="n">e</span> <span class="o">=</span> <span class="n">y</span> <span class="o">-</span> <span class="n">y_hat</span>  <span class="c1"># Vector of residuals (errors)</span>
    <span class="n">e2</span> <span class="o">=</span> <span class="n">e</span> <span class="o">**</span> <span class="mi">2</span>  <span class="c1"># The vector of squared errors.</span>
    <span class="k">return</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">e2</span> <span class="o">*</span> <span class="n">weights</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weighted_res</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">sos_weighted</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">prop_professors_by_subject</span><span class="p">))</span>
<span class="n">weighted_res</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>  message: Optimization terminated successfully.
  success: True
   status: 0
      fun: 0.0018148520779416857
        x: [ 7.139e-01  7.992e-03  1.085e+00]
      nit: 11
      jac: [-7.451e-09  2.285e-09  1.451e-08]
 hess_inv: [[ 3.246e+01 -1.768e+01 -6.389e+01]
            [-1.768e+01  1.918e+01  5.111e+00]
            [-6.389e+01  5.111e+00  2.186e+02]]
     nfev: 60
     njev: 15
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weighted_res</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.71386388, 0.00799227, 1.08466463])
</pre></div>
</div>
</div>
</div>
<p>Notice these are the same (within very close limits) to the parameters we got from Statsmodels and Sklearn:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sk_weighted</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">sk_weighted</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([0.7138681 , 0.00799134]), 1.0846520953764385)
</pre></div>
</div>
</div>
</div>
<p>We can get <code class="docutils literal notranslate"><span class="pre">minimize</span></code> even closer by setting the <code class="docutils literal notranslate"><span class="pre">tol</span></code> value for <code class="docutils literal notranslate"><span class="pre">minimize</span></code> to be a very small number. <code class="docutils literal notranslate"><span class="pre">tol</span></code> specifies how small the difference has to be when making small changes in the parameters, before <code class="docutils literal notranslate"><span class="pre">minimize</span></code> accepts it is close enough to the right answer and stops.   Put another way, it specifies the precision of the estimates.</p>
<p>In fact, to get really close, we also have to specify an (in this case) more accurate method for the optimization, rather than using the default.  We will use the <code class="docutils literal notranslate"><span class="pre">powell</span></code> method to do the search.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weighted_res_precise</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">sos_weighted</span><span class="p">,</span>
                                <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span>
                                <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">prop_professors_by_subject</span><span class="p">),</span>
                                <span class="n">method</span><span class="o">=</span><span class="s1">&#39;powell&#39;</span><span class="p">,</span>
                                <span class="n">tol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>  <span class="c1"># 0.0000000001</span>
<span class="n">weighted_res_precise</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> message: Optimization terminated successfully.
 success: True
  status: 0
     fun: 0.0018148520775737415
       x: [ 7.139e-01  7.991e-03  1.085e+00]
     nit: 7
   direc: [[-2.683e-02  2.738e-02  1.312e-02]
           [-2.747e-01 -1.944e-02  1.066e+00]
           [ 2.241e-13 -1.351e-13  7.467e-12]]
    nfev: 551
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">weighted_res_precise</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.7138681 , 0.00799134, 1.0846521 ])
</pre></div>
</div>
</div>
</div>
<p>Notice that we got very close to the Sklearn result.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sk_weighted</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">sk_weighted</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([0.7138681 , 0.00799134]), 1.0846520953764385)
</pre></div>
</div>
</div>
</div>
</section>
<section id="penalized-regression">
<h2>Penalized regression<a class="headerlink" href="#penalized-regression" title="Permalink to this heading">#</a></h2>
<p>Penalized regression is where you simultaneously minimize some cost related to the model (mis-)fit, and some cost related to the parameters of your model.</p>
<section id="ridge-regression">
<h3>Ridge regression<a class="headerlink" href="#ridge-regression" title="Permalink to this heading">#</a></h3>
<p>For example, in <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Ridge.html">ridge
regression</a>,
we try and minimize the sum of squared residuals <em>and</em> the sum of squares
of the parameters (except for from the intercept).</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">sk_ridge</span> <span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">Ridge</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mi">1</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
<span class="n">sk_ridge</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">sk_ridge</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([0.50092516, 0.15572434]), 1.4041393822652166)
</pre></div>
</div>
</div>
</div>
<p>Fit with the <code class="docutils literal notranslate"><span class="pre">minimize</span></code> cost function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sos_ridge</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="n">ss_resid</span> <span class="o">=</span> <span class="n">sos</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>  <span class="c1"># Using our sos function.</span>
    <span class="k">return</span> <span class="n">ss_resid</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">params</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
</div>
<p>Fit ridge regression with the <code class="docutils literal notranslate"><span class="pre">minimize</span></code> cost function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res_ridge</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">sos_ridge</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mf">1.0</span><span class="p">),</span>
                     <span class="n">method</span><span class="o">=</span><span class="s1">&#39;powell&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>
<span class="n">res_ridge</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.50092517, 0.15572433, 1.40413936])
</pre></div>
</div>
</div>
</div>
</section>
<section id="lasso">
<h3>LASSO<a class="headerlink" href="#lasso" title="Permalink to this heading">#</a></h3>
<p>See the <a class="reference external" href="https://scikit-learn.org/stable/modules/generated/sklearn.linear_model.Lasso.html">Scikit-learn LASSO page</a>.</p>
<p>As noted there, the cost function is:</p>
<div class="math notranslate nohighlight">
\[
\frac{1}{ 2 * n } * ||y - Xw||^2_2 + alpha * ||w||_1
\]</div>
<p><span class="math notranslate nohighlight">\(w\)</span> refers to the vector of model parameters.</p>
<p>This part of the equation:</p>
<div class="math notranslate nohighlight">
\[
||y - Xw||^2_2
\]</div>
<p>is the sum of squares of the residuals, because the residuals are <span class="math notranslate nohighlight">\(y - Xw\)</span>
(where <span class="math notranslate nohighlight">\(w\)</span> are the parameters of the model, and <span class="math notranslate nohighlight">\(Xw\)</span> are therefore the fitted
values), and the <span class="math notranslate nohighlight">\(||y - Xw||^2_2\)</span> refers to the squared <a class="reference external" href="https://mathworld.wolfram.com/L2-Norm.html">L2 vector
norm</a>, which is the same as the
sum of squares.</p>
<div class="math notranslate nohighlight">
\[
||w||_1
\]</div>
<p>is the <a class="reference external" href="https://mathworld.wolfram.com/L1-Norm.html">L1 vector norm</a> of the
parameters <span class="math notranslate nohighlight">\(w\)</span>, which is the sum of the absolute values of the parameters.</p>
<p>Let’s do that calculation, with a low <code class="docutils literal notranslate"><span class="pre">alpha</span></code> (otherwise both slopes get
forced down to zero):</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># We need LassoLars for increased accuracy.</span>
<span class="n">sk_lasso</span> <span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">LassoLars</span><span class="p">(</span><span class="n">alpha</span><span class="o">=</span><span class="mf">0.01</span><span class="p">)</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span><span class="n">clarity_easiness</span><span class="p">,</span> <span class="n">helpfulness</span><span class="p">)</span>

<span class="n">sk_lasso</span><span class="o">.</span><span class="n">coef_</span><span class="p">,</span> <span class="n">sk_lasso</span><span class="o">.</span><span class="n">intercept_</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>(array([0.56798712, 0.00366785]), 1.6398158836228247)
</pre></div>
</div>
</div>
</div>
<p>Here is the equivalent <code class="docutils literal notranslate"><span class="pre">minimize</span></code> cost function:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">sos_lasso</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="n">alpha</span><span class="p">):</span>
    <span class="n">ss_resid</span> <span class="o">=</span> <span class="n">sos</span><span class="p">(</span><span class="n">params</span><span class="p">,</span> <span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">)</span>
    <span class="n">n</span> <span class="o">=</span> <span class="nb">len</span><span class="p">(</span><span class="n">y</span><span class="p">)</span>
    <span class="n">penalty</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">np</span><span class="o">.</span><span class="n">abs</span><span class="p">(</span><span class="n">params</span><span class="p">[:</span><span class="o">-</span><span class="mi">1</span><span class="p">]))</span>
    <span class="k">return</span> <span class="mi">1</span> <span class="o">/</span> <span class="p">(</span><span class="mi">2</span> <span class="o">*</span> <span class="n">n</span><span class="p">)</span> <span class="o">*</span> <span class="n">ss_resid</span> <span class="o">+</span> <span class="n">alpha</span> <span class="o">*</span> <span class="n">penalty</span>
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res_lasso</span> <span class="o">=</span> <span class="n">minimize</span><span class="p">(</span><span class="n">sos_lasso</span><span class="p">,</span> <span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">,</span> <span class="mi">0</span><span class="p">],</span> <span class="n">args</span><span class="o">=</span><span class="p">(</span><span class="n">X</span><span class="p">,</span> <span class="n">y</span><span class="p">,</span> <span class="mf">0.01</span><span class="p">),</span>
                     <span class="n">method</span><span class="o">=</span><span class="s1">&#39;powell&#39;</span><span class="p">,</span> <span class="n">tol</span><span class="o">=</span><span class="mf">1e-10</span><span class="p">)</span>
<span class="n">res_lasso</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span> message: Optimization terminated successfully.
 success: True
  status: 0
     fun: 0.008315817048158883
       x: [ 5.680e-01  3.668e-03  1.640e+00]
     nit: 5
   direc: [[ 0.000e+00  0.000e+00  1.000e+00]
           [-4.391e-01  0.000e+00  1.629e+00]
           [-3.755e-03  3.647e-03  2.276e-03]]
    nfev: 449
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">res_lasso</span><span class="o">.</span><span class="n">x</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([0.56798713, 0.00366785, 1.63981586])
</pre></div>
</div>
</div>
</div>
</section>
</section>
<section id="cross-validation">
<h2>Cross-validation<a class="headerlink" href="#cross-validation" title="Permalink to this heading">#</a></h2>
<p>Should I add the “Easiness” regressor?  In other words, is a model that has <em>both</em> the “Clarity” and “Easiness” regressor better than a model that just has the “Clarity” regressor?</p>
<p>We could start by comparing the remaining (residual) sum of squares for the two models.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Make a single-column dataframe with Clarity</span>
<span class="n">clarity_df</span> <span class="o">=</span> <span class="n">clarity_easiness</span><span class="p">[[</span><span class="s1">&#39;Clarity&#39;</span><span class="p">]]</span>
<span class="n">clarity_df</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Clarity</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.756147</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3.487379</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.608331</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.909520</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3.788818</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
    </tr>
    <tr>
      <th>70</th>
      <td>3.932991</td>
    </tr>
    <tr>
      <th>71</th>
      <td>3.636182</td>
    </tr>
    <tr>
      <th>72</th>
      <td>3.749000</td>
    </tr>
    <tr>
      <th>73</th>
      <td>3.441923</td>
    </tr>
    <tr>
      <th>74</th>
      <td>3.927255</td>
    </tr>
  </tbody>
</table>
<p>75 rows × 1 columns</p>
</div></div></div>
</div>
<p>First we fit a linear model with the single-regressor “Clarity” model, and calculate the sum of squared residuals:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">single_fit</span> <span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">clarity_df</span><span class="p">,</span> <span class="n">helpfulness</span><span class="p">)</span>
<span class="n">single_y_hat</span> <span class="o">=</span> <span class="n">single_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">clarity_df</span><span class="p">)</span>
<span class="n">single_ss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">helpfulness</span> <span class="o">-</span> <span class="n">single_y_hat</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">single_ss</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.18768752586074872
</pre></div>
</div>
</div>
</div>
<p>Then we do the same for the two-regressor model, with “Clarity” and “Easiness”:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">both_fit</span> <span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">clarity_easiness</span><span class="p">,</span> <span class="n">helpfulness</span><span class="p">)</span>
<span class="n">both_y_hat</span> <span class="o">=</span> <span class="n">both_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">clarity_easiness</span><span class="p">)</span>
<span class="n">both_ss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">helpfulness</span> <span class="o">-</span> <span class="n">both_y_hat</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">both_ss</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.18759984412745978
</pre></div>
</div>
</div>
</div>
<p>There’s a small difference:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">single_ss</span> <span class="o">-</span> <span class="n">both_ss</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>8.768173328893569e-05
</pre></div>
</div>
</div>
</div>
<p>Notice the sum of squared <span class="math notranslate nohighlight">\(SS_{\text{resid}}\)</span> is very slightly lower for the model with “Easiness”.   But in fact, we could show that we would reduce the error by adding almost any regressor to the model.  It turns out that the error can only ever go down, or stay the same, by adding another regressor.</p>
<p>In fact — let’s try it.  We’ll add a regressor of random numbers to the “Clarity” regressor, and see how it fares:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">rng</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">random</span><span class="o">.</span><span class="n">default_rng</span><span class="p">()</span>

<span class="n">with_random</span> <span class="o">=</span> <span class="n">clarity_df</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="n">with_random</span><span class="p">[</span><span class="s1">&#39;random&#39;</span><span class="p">]</span> <span class="o">=</span> <span class="n">rng</span><span class="o">.</span><span class="n">normal</span><span class="p">(</span><span class="n">size</span><span class="o">=</span><span class="n">n</span><span class="p">)</span>
<span class="n">with_random</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Clarity</th>
      <th>random</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>3.756147</td>
      <td>-0.087181</td>
    </tr>
    <tr>
      <th>1</th>
      <td>3.487379</td>
      <td>0.118091</td>
    </tr>
    <tr>
      <th>2</th>
      <td>3.608331</td>
      <td>-0.378918</td>
    </tr>
    <tr>
      <th>3</th>
      <td>3.909520</td>
      <td>0.972522</td>
    </tr>
    <tr>
      <th>4</th>
      <td>3.788818</td>
      <td>0.054188</td>
    </tr>
    <tr>
      <th>...</th>
      <td>...</td>
      <td>...</td>
    </tr>
    <tr>
      <th>70</th>
      <td>3.932991</td>
      <td>1.569472</td>
    </tr>
    <tr>
      <th>71</th>
      <td>3.636182</td>
      <td>1.258132</td>
    </tr>
    <tr>
      <th>72</th>
      <td>3.749000</td>
      <td>0.894692</td>
    </tr>
    <tr>
      <th>73</th>
      <td>3.441923</td>
      <td>-0.136654</td>
    </tr>
    <tr>
      <th>74</th>
      <td>3.927255</td>
      <td>0.000174</td>
    </tr>
  </tbody>
</table>
<p>75 rows × 2 columns</p>
</div></div></div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">random_fit</span> <span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">with_random</span><span class="p">,</span> <span class="n">helpfulness</span><span class="p">)</span>
<span class="n">random_y_hat</span> <span class="o">=</span> <span class="n">random_fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">with_random</span><span class="p">)</span>
<span class="n">random_ss</span> <span class="o">=</span> <span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">((</span><span class="n">helpfulness</span> <span class="o">-</span> <span class="n">random_y_hat</span><span class="p">)</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
<span class="n">random_ss</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.18254598800451358
</pre></div>
</div>
</div>
</div>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">single_ss</span> <span class="o">-</span> <span class="n">random_ss</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.00514153785623514
</pre></div>
</div>
</div>
</div>
<p>Notice the random regressor does around as well (often better) than the “Easiness” regressor.  That’s not a good sign for the usefulness of “Easiness”.</p>
<p>We would like a better test — one that tells us whether our model is
better able to predict a <em>new</em> value that the model hasn’t seen before.</p>
<p>We can do this with <em>cross-validation</em>.  <em>Leave one out</em> is a simple
form of cross-validation.  The procedure is, that we take each row in
the dataset in turn.  We drop that row from the dataset, and fit the
model (estimate the parameters) on that dataset, with the row dropped.
Then we use that model to <em>predict</em> the value from the row that we
dropped — because this a value we did not use to build the model.  We do this for all rows, making a model and predicting the value from the row we dropped.  Then we ask — how well do the predicted values do in predicting the actual values?</p>
<p>This is how that would work for the first row:</p>
<ul class="simple">
<li><p>Drop the first row and keep it somewhere.</p></li>
<li><p>Run the model on the remaining rows.</p></li>
<li><p>Use model to predict target value for first row.</p></li>
<li><p>Store prediction.</p></li>
</ul>
<p>In code that might look like this:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">row0_label</span> <span class="o">=</span> <span class="mi">0</span>  <span class="c1"># Row label of the first row.</span>
<span class="c1"># Row to drop, as a data frame:</span>
<span class="n">dropped_row</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">row0_label</span><span class="p">:</span><span class="n">row0_label</span><span class="p">]</span>
<span class="n">dropped_row</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_html"><div>
<style scoped>
    .dataframe tbody tr th:only-of-type {
        vertical-align: middle;
    }

    .dataframe tbody tr th {
        vertical-align: top;
    }

    .dataframe thead th {
        text-align: right;
    }
</style>
<table border="1" class="dataframe">
  <thead>
    <tr style="text-align: right;">
      <th></th>
      <th>Discipline</th>
      <th>Number of Professors</th>
      <th>Clarity</th>
      <th>Helpfulness</th>
      <th>Overall Quality</th>
      <th>Easiness</th>
    </tr>
  </thead>
  <tbody>
    <tr>
      <th>0</th>
      <td>English</td>
      <td>23343</td>
      <td>3.756147</td>
      <td>3.821866</td>
      <td>3.791364</td>
      <td>3.162754</td>
    </tr>
  </tbody>
</table>
</div></div></div>
</div>
<p>We’ll be using these columns for the design and target:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">x_cols</span> <span class="o">=</span> <span class="p">[</span><span class="s1">&#39;Clarity&#39;</span><span class="p">,</span> <span class="s1">&#39;Easiness&#39;</span><span class="p">]</span>
<span class="n">y_col</span> <span class="o">=</span> <span class="s1">&#39;Helpfulness&#39;</span>
</pre></div>
</div>
</div>
</div>
<p>Fit model with remaining rows, and predict target variable for first
row:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="c1"># Dataframe without dropped row</span>
<span class="n">remaining_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">row0_label</span><span class="p">)</span>
<span class="c1"># Fit on everything but the dropped row.</span>
<span class="n">fit</span> <span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
    <span class="n">remaining_df</span><span class="p">[</span><span class="n">x_cols</span><span class="p">],</span>
    <span class="n">remaining_df</span><span class="p">[</span><span class="n">y_col</span><span class="p">])</span>
<span class="c1"># Use fit to predict the dropped row.</span>
<span class="n">fitted_val</span> <span class="o">=</span> <span class="n">fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dropped_row</span><span class="p">[</span><span class="n">x_cols</span><span class="p">])</span>
<span class="n">fitted_val</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>array([3.79787918])
</pre></div>
</div>
</div>
</div>
<p>Then we keep going to generate a fitted value for every row.</p>
<p>Here’s a function to do the leave-one-out fit for a given row label:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="k">def</span> <span class="nf">drop_and_predict</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="n">x_cols</span><span class="p">,</span> <span class="n">y_col</span><span class="p">,</span> <span class="n">row_label</span><span class="p">):</span>
<span class="w">    </span><span class="sd">&quot;&quot;&quot; Drop value identified by `row_label`, fit with rest and predict</span>

<span class="sd">    Parameters</span>
<span class="sd">    ----------</span>
<span class="sd">    df : DataFrame</span>
<span class="sd">    x_cols : sequence</span>
<span class="sd">        Sequence of column labels defining regressors.</span>
<span class="sd">    y_col : str</span>
<span class="sd">        Column label for target variable.</span>
<span class="sd">    row_label : object</span>
<span class="sd">        Row label of row to drop</span>

<span class="sd">    Returns</span>
<span class="sd">    -------</span>
<span class="sd">    fitted : scalar</span>
<span class="sd">        Fitted value for column `y_col` in row labeled `row_label`,</span>
<span class="sd">        using fit from all rows except row labeled `row_label`.</span>
<span class="sd">    &quot;&quot;&quot;</span>
    <span class="n">dropped_row</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">row_label</span><span class="p">:</span><span class="n">row_label</span><span class="p">]</span>
    <span class="c1"># Dataframe without dropped row</span>
    <span class="n">remaining_df</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">drop</span><span class="p">(</span><span class="n">index</span><span class="o">=</span><span class="n">row_label</span><span class="p">)</span>
    <span class="c1"># Fit on everything but the dropped row.</span>
    <span class="n">fit</span> <span class="o">=</span> <span class="n">sklm</span><span class="o">.</span><span class="n">LinearRegression</span><span class="p">()</span><span class="o">.</span><span class="n">fit</span><span class="p">(</span>
        <span class="n">remaining_df</span><span class="p">[</span><span class="n">x_cols</span><span class="p">],</span>
        <span class="n">remaining_df</span><span class="p">[</span><span class="n">y_col</span><span class="p">])</span>
    <span class="c1"># Use fit to predict target in the dropped row, and return.</span>
    <span class="k">return</span> <span class="n">fit</span><span class="o">.</span><span class="n">predict</span><span class="p">(</span><span class="n">dropped_row</span><span class="p">[</span><span class="n">x_cols</span><span class="p">])[</span><span class="mi">0</span><span class="p">]</span>
</pre></div>
</div>
</div>
</div>
<p>Use <code class="docutils literal notranslate"><span class="pre">drop_and_predict</span></code> to build a model for all rows but the first, as
above, and then predict the “Helpfulness” value of the first row.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">actual_value</span> <span class="o">=</span> <span class="n">df</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="mi">0</span><span class="p">,</span> <span class="s1">&#39;Helpfulness&#39;</span><span class="p">]</span>
<span class="n">predicted_value</span> <span class="o">=</span> <span class="n">drop_and_predict</span><span class="p">(</span><span class="n">df</span><span class="p">,</span>
                                   <span class="p">[</span><span class="s1">&#39;Clarity&#39;</span><span class="p">,</span> <span class="s1">&#39;Easiness&#39;</span><span class="p">],</span>
                                   <span class="s1">&#39;Helpfulness&#39;</span><span class="p">,</span>
                                   <span class="mi">0</span><span class="p">)</span>
<span class="n">predicted_value</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>3.7978791792022397
</pre></div>
</div>
</div>
</div>
<p>Fit the model, with both “Clarity” and “Easiness”, and drop / predict
each “Helpfulness” value.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted_with_easiness</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Helpfulness&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">fitted</span> <span class="o">=</span> <span class="n">drop_and_predict</span><span class="p">(</span><span class="n">df</span><span class="p">,</span>
                              <span class="p">[</span><span class="s1">&#39;Clarity&#39;</span><span class="p">,</span> <span class="s1">&#39;Easiness&#39;</span><span class="p">],</span>
                              <span class="s1">&#39;Helpfulness&#39;</span><span class="p">,</span>
                              <span class="n">label</span><span class="p">)</span>
    <span class="n">predicted_with_easiness</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">fitted</span>
<span class="n">predicted_with_easiness</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0     3.797879
1     3.568443
2     3.673608
3     3.928563
4     3.829398
        ...   
70    3.945049
71    3.697332
72    3.790545
73    3.534346
74    3.944375
Name: Helpfulness, Length: 75, dtype: float64
</pre></div>
</div>
</div>
</div>
<p>Get the sum of squared residuals for these predictions:</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">error_both</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Helpfulness&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">predicted_with_easiness</span>
<span class="c1"># Sum of squared prediction errors for larger model.</span>
<span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">error_both</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.20079738301650638
</pre></div>
</div>
</div>
</div>
<p>Do the same for the model with “Clarity” only.</p>
<div class="cell docutils container">
<div class="cell_input docutils container">
<div class="highlight-ipython3 notranslate"><div class="highlight"><pre><span></span><span class="n">predicted_without_easiness</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Helpfulness&#39;</span><span class="p">]</span><span class="o">.</span><span class="n">copy</span><span class="p">()</span>
<span class="k">for</span> <span class="n">label</span> <span class="ow">in</span> <span class="n">df</span><span class="o">.</span><span class="n">index</span><span class="p">:</span>
    <span class="n">fitted</span> <span class="o">=</span> <span class="n">drop_and_predict</span><span class="p">(</span><span class="n">df</span><span class="p">,</span> <span class="p">[</span><span class="s1">&#39;Clarity&#39;</span><span class="p">],</span> <span class="p">[</span><span class="s1">&#39;Helpfulness&#39;</span><span class="p">],</span> <span class="n">label</span><span class="p">)</span>
    <span class="n">predicted_without_easiness</span><span class="o">.</span><span class="n">loc</span><span class="p">[</span><span class="n">label</span><span class="p">]</span> <span class="o">=</span> <span class="n">fitted</span>
<span class="n">error_just_one</span> <span class="o">=</span> <span class="n">df</span><span class="p">[</span><span class="s1">&#39;Helpfulness&#39;</span><span class="p">]</span> <span class="o">-</span> <span class="n">predicted_without_easiness</span>
<span class="c1"># Sum of squared prediction errors for smaller model.</span>
<span class="n">np</span><span class="o">.</span><span class="n">sum</span><span class="p">(</span><span class="n">error_just_one</span> <span class="o">**</span> <span class="mi">2</span><span class="p">)</span>
</pre></div>
</div>
</div>
<div class="cell_output docutils container">
<div class="output text_plain highlight-myst-ansi notranslate"><div class="highlight"><pre><span></span>0.1966941619436559
</pre></div>
</div>
</div>
</div>
<p>The model without “Easiness” does a slightly <em>better</em> job of predicting, with leave-one-out cross-validation.</p>
</section>
</section>

    <script type="text/x-thebe-config">
    {
        requestKernel: true,
        binderOptions: {
            repo: "lisds/dsip",
            ref: "main",
        },
        codeMirrorConfig: {
            theme: "abcdef",
            mode: "python"
        },
        kernelOptions: {
            name: "python3",
            path: "./."
        },
        predefinedOutput: true
    }
    </script>
    <script>kernelName = 'python3'</script>

                </article>
              

              
              
              
              
                <footer class="prev-next-footer">
                  
<div class="prev-next-area">
    <a class="left-prev"
       href="logistic_regression_cross_validation.html"
       title="previous page">
      <i class="fa-solid fa-angle-left"></i>
      <div class="prev-next-info">
        <p class="prev-next-subtitle">previous</p>
        <p class="prev-next-title">Multiple Logistic Regression, Model Selection and Cross-validation</p>
      </div>
    </a>
    <a class="right-next"
       href="matrix_notation.html"
       title="next page">
      <div class="prev-next-info">
        <p class="prev-next-subtitle">next</p>
        <p class="prev-next-title">Expressing the linear model with matrices</p>
      </div>
      <i class="fa-solid fa-angle-right"></i>
    </a>
</div>
                </footer>
              
            </div>
            
            
              
                <div class="bd-sidebar-secondary bd-toc"><div class="sidebar-secondary-items sidebar-secondary__inner">


  <div class="sidebar-secondary-item">
  <div class="page-toc tocsection onthispage">
    <i class="fa-solid fa-list"></i> Contents
  </div>
  <nav class="bd-toc-nav page-toc">
    <ul class="visible nav section-nav flex-column">
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-fitted-values-and-scikit-learn">The fitted values and Scikit-learn</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#a-short-diversion-writing-the-mean-in-symbols">A short diversion — writing the mean in symbols</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#the-long-and-the-short-of-r-2">The long and the short of <span class="math notranslate nohighlight">\(R^2\)</span></a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#r-2-for-another-reduced-model"><span class="math notranslate nohighlight">\(R^2\)</span> for another, reduced model</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#on-weights-and-a-weighted-mean">On weights, and a weighted mean</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#fitting-with-weights">Fitting with weights</a></li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#penalized-regression">Penalized regression</a><ul class="nav section-nav flex-column">
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#ridge-regression">Ridge regression</a></li>
<li class="toc-h3 nav-item toc-entry"><a class="reference internal nav-link" href="#lasso">LASSO</a></li>
</ul>
</li>
<li class="toc-h2 nav-item toc-entry"><a class="reference internal nav-link" href="#cross-validation">Cross-validation</a></li>
</ul>
  </nav></div>

</div></div>
              
            
          </div>
          <footer class="bd-footer-content">
            
<div class="bd-footer-content__inner container">
  
  <div class="footer-item">
    
<p class="component-author">
By Matthew Brett and Peter Rush
</p>

  </div>
  
  <div class="footer-item">
    

  <p class="copyright">
    
      © Copyright 2023.
      <br/>
    
  </p>

  </div>
  
  <div class="footer-item">
    
  </div>
  
  <div class="footer-item">
    
  </div>
  
</div>
          </footer>
        

      </main>
    </div>
  </div>
  
  <!-- Scripts loaded after <body> so the DOM is not blocked -->
  <script src="_static/scripts/bootstrap.js?digest=8d27b9dea8ad943066ae"></script>
<script src="_static/scripts/pydata-sphinx-theme.js?digest=8d27b9dea8ad943066ae"></script>

  <footer class="bd-footer">
  </footer>
  </body>
</html>